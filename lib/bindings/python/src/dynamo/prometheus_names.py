# SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
# SPDX-License-Identifier: Apache-2.0

"""
Python constants for Prometheus metric names

AUTO-GENERATED from lib/runtime/src/metrics/prometheus_names.rs
DO NOT EDIT THIS FILE MANUALLY

To regenerate this file after modifying lib/runtime/src/metrics/prometheus_names.rs:
    cargo run -p dynamo-codegen --bin gen-python-prometheus-names

This module provides pure Python access to Prometheus metric name constants
without requiring Rust bindings.

Usage (both patterns supported):
    # Pattern 1: Import module
    from dynamo import prometheus_names
    print(prometheus_names.frontend_service.REQUESTS_TOTAL)  # "requests_total"
    print(prometheus_names.kvstats.ACTIVE_BLOCKS)  # "kvstats_active_blocks"

    # Pattern 2: Import specific classes
    from dynamo.prometheus_names import frontend_service, kvstats
    print(frontend_service.REQUESTS_TOTAL)  # "requests_total"
    print(kvstats.ACTIVE_BLOCKS)  # "kvstats_active_blocks"
"""

from __future__ import annotations


class distributed_runtime:
    """DistributedRuntime core metrics"""

    # Total uptime of the DistributedRuntime in seconds
    UPTIME_SECONDS = "uptime_seconds"


class frontend_service:
    """Frontend service metrics (LLM HTTP service)"""

    # Environment variable that overrides the default metric prefix
    METRICS_PREFIX_ENV = "DYN_METRICS_PREFIX"
    # Total number of LLM requests processed
    REQUESTS_TOTAL = "requests_total"
    # Number of requests waiting in HTTP queue before receiving the first response (gauge)
    QUEUED_REQUESTS = "queued_requests"
    # Number of inflight/concurrent requests going to the engine (vLLM, SGLang, ...)
    # Note: This is a gauge metric (current state) that can go up and down, so no _total suffix
    INFLIGHT_REQUESTS = "inflight_requests"
    # Number of disconnected clients (gauge that can go up and down)
    DISCONNECTED_CLIENTS = "disconnected_clients"
    # Duration of LLM requests
    REQUEST_DURATION_SECONDS = "request_duration_seconds"
    # Input sequence length in tokens
    INPUT_SEQUENCE_TOKENS = "input_sequence_tokens"
    # Output sequence length in tokens
    OUTPUT_SEQUENCE_TOKENS = "output_sequence_tokens"
    # Number of cached tokens (prefix cache hits) per request
    CACHED_TOKENS = "cached_tokens"
    # Total number of output tokens generated (counter that updates in real-time)
    OUTPUT_TOKENS_TOTAL = "output_tokens_total"
    # Time to first token in seconds
    TIME_TO_FIRST_TOKEN_SECONDS = "time_to_first_token_seconds"
    # Inter-token latency in seconds
    INTER_TOKEN_LATENCY_SECONDS = "inter_token_latency_seconds"
    # Model configuration metrics
    # Runtime config metrics (from ModelRuntimeConfig):
    # Total KV blocks available for a worker serving the model
    MODEL_TOTAL_KV_BLOCKS = "model_total_kv_blocks"
    # Maximum number of sequences for a worker serving the model (runtime config)
    MODEL_MAX_NUM_SEQS = "model_max_num_seqs"
    # Maximum number of batched tokens for a worker serving the model (runtime config)
    MODEL_MAX_NUM_BATCHED_TOKENS = "model_max_num_batched_tokens"
    # MDC metrics (from ModelDeploymentCard):
    # Maximum context length for a worker serving the model (MDC)
    MODEL_CONTEXT_LENGTH = "model_context_length"
    # KV cache block size for a worker serving the model (MDC)
    MODEL_KV_CACHE_BLOCK_SIZE = "model_kv_cache_block_size"
    # Request migration limit for a worker serving the model (MDC)
    MODEL_MIGRATION_LIMIT = "model_migration_limit"
    # Total number of request migrations due to worker unavailability
    MODEL_MIGRATION_TOTAL = "model_migration_total"
    # Label name for the type of migration
    MIGRATION_TYPE_LABEL = "migration_type"


class kvbm:
    """KVBM"""

    # The number of offload blocks from device to host
    OFFLOAD_BLOCKS_D2H = "offload_blocks_d2h"
    # The number of offload blocks from host to disk
    OFFLOAD_BLOCKS_H2D = "offload_blocks_h2d"
    # The number of offload blocks from device to disk (bypassing host memory)
    OFFLOAD_BLOCKS_D2D = "offload_blocks_d2d"
    # The number of onboard blocks from host to device
    ONBOARD_BLOCKS_H2D = "onboard_blocks_h2d"
    # The number of onboard blocks from disk to device
    ONBOARD_BLOCKS_D2D = "onboard_blocks_d2d"
    # The number of matched tokens
    MATCHED_TOKENS = "matched_tokens"
    # Host cache hit rate (0.0-1.0) from the sliding window
    HOST_CACHE_HIT_RATE = "host_cache_hit_rate"
    # Disk cache hit rate (0.0-1.0) from the sliding window
    DISK_CACHE_HIT_RATE = "disk_cache_hit_rate"


class kvrouter:
    # Number of KV cache events applied to the index (including status)
    KV_CACHE_EVENTS_APPLIED = "kv_cache_events_applied"


class kvstats:
    """KvStats metrics from LLM workers"""

    # Prefix for all KvStats metrics
    PREFIX = ""
    # Number of active KV cache blocks currently in use
    ACTIVE_BLOCKS = "kvstats_active_blocks"
    # Total number of KV cache blocks available
    TOTAL_BLOCKS = "kvstats_total_blocks"
    # GPU cache usage as a percentage (0.0-1.0)
    GPU_CACHE_USAGE_PERCENT = "kvstats_gpu_cache_usage_percent"
    # GPU prefix cache hit rate as a percentage (0.0-1.0)
    GPU_PREFIX_CACHE_HIT_RATE = "kvstats_gpu_prefix_cache_hit_rate"


class labels:
    """Automatically inserted Prometheus label names used across the metrics system"""

    # Label for component identification
    COMPONENT = "dynamo_component"
    # Label for namespace identification
    NAMESPACE = "dynamo_namespace"
    # Label for endpoint identification
    ENDPOINT = "dynamo_endpoint"


class name_prefix:
    """Metric name prefixes used across the metrics system"""

    # Prefix for all Prometheus metric names.
    COMPONENT = "dynamo_component"
    # Prefix for frontend service metrics
    FRONTEND = "dynamo_frontend"


class task_tracker:
    """Task tracker Prometheus metric name suffixes"""

    # Total number of tasks issued/submitted
    TASKS_ISSUED_TOTAL = "tasks_issued_total"
    # Total number of tasks started
    TASKS_STARTED_TOTAL = "tasks_started_total"
    # Total number of successfully completed tasks
    TASKS_SUCCESS_TOTAL = "tasks_success_total"
    # Total number of cancelled tasks
    TASKS_CANCELLED_TOTAL = "tasks_cancelled_total"
    # Total number of failed tasks
    TASKS_FAILED_TOTAL = "tasks_failed_total"
    # Total number of rejected tasks
    TASKS_REJECTED_TOTAL = "tasks_rejected_total"


class work_handler:
    """Work handler Prometheus metric names"""

    # Total number of requests processed by work handler
    REQUESTS_TOTAL = "requests_total"
    # Total number of bytes received in requests by work handler
    REQUEST_BYTES_TOTAL = "request_bytes_total"
    # Total number of bytes sent in responses by work handler
    RESPONSE_BYTES_TOTAL = "response_bytes_total"
    # Number of requests currently being processed by work handler
    # Note: This is a gauge metric (current state) that can go up and down, so no _total suffix
    INFLIGHT_REQUESTS = "inflight_requests"
    # Time spent processing requests by work handler (histogram)
    REQUEST_DURATION_SECONDS = "request_duration_seconds"
    # Total number of errors in work handler processing
    ERRORS_TOTAL = "errors_total"
    # Label name for error type classification
    ERROR_TYPE_LABEL = "error_type"
